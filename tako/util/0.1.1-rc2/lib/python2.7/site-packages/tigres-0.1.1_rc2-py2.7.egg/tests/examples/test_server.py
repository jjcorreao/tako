from multiprocessing.managers import SyncManager

try:
    import queue
except ImportError:
    import Queue as queue
import time
import marshal

try:
    import cloud
except:
    pass

IP = 'localhost'
PORTNUM = 55444
AUTHKEY = 'shufflin'


def make_server_manager(port, authkey):
    job_q = queue.Queue()
    result_q = queue.Queue()

    class JobQueueManager(SyncManager):
        pass

    JobQueueManager.register('get_job_q', callable=lambda: job_q)
    JobQueueManager.register('get_result_q', callable=lambda: result_q)

    manager = JobQueueManager(address=('', port), authkey=authkey)
    manager.start()
    print(('Server started at port %s' % port))
    return manager


def make_nums(N):
    nums = [999999999999]
    for i in range(N):
        nums.append(nums[-1] + 2)
    return nums


def do_something_else(a):
    return a - 100


def do_something(a):
    return do_something_else(a * a)


def runserver():
    manager = make_server_manager(PORTNUM, AUTHKEY)
    shared_job_q = manager.get_job_q()
    shared_result_q = manager.get_result_q()

    N = 9999
    nums = make_nums(N)
    chunksize = 43
    code = cloud.serialization.cloudpickle.dumps(do_something)
    print(code)

    for i in range(0, len(nums), chunksize):
        #print 'putting chunk %s:%s in job Q' % (i, i + chunksize)
        code_string = marshal.dumps(do_something.__code__)
        shared_job_q.put((code, i))

    while not shared_job_q.empty():
        pass

    while not shared_result_q.empty():
        output = shared_result_q.get()
        print(output)

    print('--- DONE ---')
    time.sleep(2)
    manager.shutdown()


if __name__ == '__main__':
    runserver()
    pass