"""
Unit tests for runtime execution graph file (.dot) generation

created on 2013-05-20 by Gilberto Pastorello <gzpastorello@lbl.gov>
"""
try:
    xrange
    range = xrange
except NameError:
    pass
import unittest
import random
from datetime import datetime
from tigres import *


class TestGraph(unittest.TestCase):
    def split_list(self, alist, wanted_parts=1):
        length = len(alist)
        return [alist[i * length // wanted_parts: (i + 1) * length // wanted_parts]
                for i in range(wanted_parts)]

    def setUp(self):
        pass

    def tearDown(self):
        """Remove generated dot files"""
        import os
        import glob

        for logfile in glob.glob("Graph*.dot"):
            os.unlink(logfile)

    def doNothing(self, arg):
        return

    def notest_generate_graph(self):
        """
            Tests runtime graph file generation providing all the parameters at init() and calling finalize()
        """
        random.seed()

        base = '/tmp/graph_tests_init_all_{}{}.{}'
        ts = datetime.now().strftime('%Y-%m-%dT%H-%M-%S-%f')

        workflow_name = 'New Test'
        log_name = base.format(ts, '', 'log')

        full_name_dot = base.format(ts, '_full', 'dot')
        exec_name_dot = base.format(ts, '_exec', 'dot')
        data_name_dot = base.format(ts, '_data', 'dot')

        #Changes made here. Added JSON stuff
        full_name_json = base.format(ts, '_full', 'json')
        exec_name_json = base.format(ts, '_exec', 'json')
        data_name_json = base.format(ts, '_data', 'json')

        #overlay_name = base.format(ts, '_over', 'dot')

        Program(name=workflow_name,
                log_dest=log_name,
                dot_full_filename=full_name_dot,
                dot_exec_filename=exec_name_dot,
                dot_data_filename=data_name_dot,
                #I made some changes here. Added json stuff.
                json_full_filename=full_name_json,
                json_exec_filename=exec_name_json,
                json_data_filename=data_name_json,
                dot_data_include_nodep=False)

        nelems = random.randint(50, 60)

        seq_task_array = []
        par_task_array = []
        split_task_array = []
        merge_task_array = []
        input_array = []
        tasks = []
        global_task_array = []

        for i in range(nelems):
            task_types = InputTypes("task{}_types".format(i), [int])

            t = Task("seq_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            seq_task_array.append(t)

            t = Task("par_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            par_task_array.append(t)

            t = Task("spl_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            split_task_array.append(t)

            t = Task("mer_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            merge_task_array.append(t)

            input_array.append([i])

        """Do Partitioning of each task array into many individual templates"""


        #Number of partitions for each type of task
        lowerBound = 0
        upperBound = 7
        seqPartitions = random.randint(lowerBound, upperBound)
        parPartitions = random.randint(lowerBound, upperBound)
        mergePartitions = random.randint(lowerBound, upperBound)
        splitPartitions = random.randint(lowerBound, upperBound)

        #need to copy and partition input array
        i1 = list(input_array)
        i2 = list(input_array)
        i3 = list(input_array)
        i4 = list(input_array)

        seqTemplates = self.split_list(seq_task_array, seqPartitions)
        i1 = self.split_list(i1, seqPartitions)
        parTemplates = self.split_list(par_task_array, parPartitions)
        i2 = self.split_list(i2, parPartitions)
        mergeTemplates = self.split_list(split_task_array, mergePartitions)
        i3 = self.split_list(i3, mergePartitions)
        splitTemplates = self.split_list(merge_task_array, splitPartitions)
        i4 = self.split_list(i4, splitPartitions)

        # Sequence
        for index, seq_set in enumerate(seqTemplates):
            tempArray = []
            input_array = InputArray("inputs", i1[index])
            seq_task_array = TaskArray('Seq Array', seq_set)
            seq_result = sequence("Seq Graph Test", seq_task_array, input_array)

            #I had trouble getting everything to state without using this syntax. Cleaner solution?
            for i in seq_task_array:
                tempArray.append(i)
            tasks.append(tempArray)

        # Parallel
        for index, seq_set in enumerate(parTemplates):
            tempArray = []
            input_array = InputArray("inputs", i2[index])
            par_task_array = TaskArray('Par Array', seq_set)
            par_result_list = parallel("Par Graph Test", par_task_array, input_array)
            for i in par_task_array:
                tempArray.append(i)
            tasks.append(tempArray)

        # Merge
        for index, seq_set in enumerate(mergeTemplates):
            tempArray = []
            input_array = InputArray("inputs", i3[index])
            merge_task_array = TaskArray('Merge Array', seq_set)
            t = Task("mer_final", FUNCTION, self.doNothing, task_types, None)
            merge_task = t
            merge_result = merge("Merge Graph Test", merge_task_array, input_array, merge_task, [0])

            tempArray.extend(merge_task_array)
            tempArray.append(merge_task)
            tasks.append(tempArray)

        # Split
        for index, seq_set in enumerate(splitTemplates):
            tempArray = []
            print((i4[index]))
            input_array = InputArray("inputs", i4[index])
            split_task_array = TaskArray('Split Array', seq_set)
            print((len(split_task_array), "sentinel"))
            print((len(input_array), "sentinel 2"))
            print("\n")
            t = Task("spl_first", FUNCTION, self.doNothing, task_types, None)
            split_task = t
            split_result_list = split("Split Graph Test", split_task, InputArray("input", [0]), split_task_array,
                                      input_array)
            tempArray.extend(split_task_array)
            tempArray.append(split_task)
            tasks.append(tempArray)

        random.shuffle(tasks)

        #create an array of tasks in execution order
        for task in tasks:
            global_task_array.extend(task)

        index = ''
        for index, task in enumerate(reversed(global_task_array)):
            #upperBound = (len(global_task_array)-1)-(index-1)
            length = len(global_task_array) - 1
            if index < length:

                upperBound = index + 1
                for i in range(random.randint(0, 2)):
                    random_dependency_index = random.randint(upperBound, length)
                    task.add_data_dependency(global_task_array[random_dependency_index])
            else:
                pass
            index = index
        end()

    def notest_generate_graph_single_graph(self):
        """
            Tests runtime graph file generation providing one filename at init() and calling finalize()
        """
        base = '/tmp/graph_tests_init_single_{}{}.{}'
        ts = datetime.now().strftime('%Y-%m-%dT%H-%M-%S-%f')

        workflow_name = 'Graph Test (init single dot file)'
        log_name = base.format(ts, '', 'log')
        exec_name = base.format(ts, '_exec', 'dot')

        start(name=workflow_name,
              log_dest=log_name,
              dot_exec_filename=exec_name, )

        nelems = 15

        #Task("Task_N", FUNCTION/EXECUTABLE, function, task2_types, None)

        seq_task_array = []
        par_task_array = []
        split_task_array = []
        merge_task_array = []
        input_array = []
        tasks = []
        global_task_array = []

        for i in range(nelems):
            task_types = InputTypes("task{}_types".format(i), [int])
            t = Task("seq{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            seq_task_array.append(t)

            t = Task("par_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            par_task_array.append(t)

            t = Task("spl_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            split_task_array.append(t)

            t = Task("mer_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            merge_task_array.append(t)

            input_array.append([i])

        input_array = InputArray("inputs", input_array)
        # Sequence
        tempArray = []
        seq_task_array = TaskArray('Seq Array', seq_task_array)
        seq_result = sequence("Seq Graph Test", seq_task_array, input_array)

        for i in seq_task_array:
            tempArray.append(i)
        tasks.append(tempArray)

        tempArray = []
        # Split
        split_task_array = TaskArray('Split Array', split_task_array)
        t = Task("spl_first", FUNCTION, self.doNothing, task_types, None)
        split_task = t
        split_result_list = split("Split Graph Test", split_task, [0], split_task_array, input_array)

        tempArray.extend(split_task_array)
        tempArray.append(split_task)
        tasks.append(tempArray)

        # Parallel
        tempArray = []
        par_task_array = TaskArray('Par Array', par_task_array)
        par_result_list = parallel("Par Graph Test", par_task_array, input_array)

        for i in par_task_array:
            tempArray.append(i)
        tasks.append(tempArray)

        tempArray = []
        # Merge
        merge_task_array = TaskArray('Merge Array', merge_task_array)
        t = Task("mer_final", FUNCTION, self.doNothing, task_types, None)
        merge_task = t
        merge_result = merge("Merge Graph Test", merge_task_array, input_array, merge_task, [0])

        tempArray.extend(merge_task_array)
        tempArray.append(merge_task)
        tasks.append(tempArray)

        random.shuffle(tasks)

        #create an array of tasks in execution order
        for task in tasks:
            global_task_array.extend(task)

        for index, task in enumerate(reversed(global_task_array)):
            upperBound = (len(global_task_array) - 1) - index
            for i in range(random.randint(0, 2)):
                random_dependency_index = random.randint(0, upperBound)
                task.add_data_dependency(global_task_array[random_dependency_index])
        end()

    def notest_generate_graph_default_names(self):
        """
            Tests runtime graph file generation providing only which graphs should be generated at init() and calling finalize()
        """
        OUT_TASK = "(Task_{id1}, FUNCTION, {id2}, task{id3}_types, None)"
        base = '/tmp/graph_tests_init_all_{}{}.{}'
        ts = datetime.now().strftime('%Y-%m-%dT%H-%M-%S-%f')

        workflow_name = 'Graph Test (init all dot files)'
        log_name = base.format(ts, '', 'log')

        start(name=workflow_name,
              log_dest=log_name,
              dot_gen_full=False,
              dot_gen_exec=True,
              dot_gen_data=False,
              dot_data_include_nodep=False)

        nelems = 15

        seq_task_array = []
        par_task_array = []
        split_task_array = []
        merge_task_array = []
        input_array = []
        for i in range(nelems):
            task_types = InputTypes("task{}_types".format(i), [int])
            t = Task("seq_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            seq_task_array.append(t)

            t = Task("par_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            par_task_array.append(t)

            t = Task("spl_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            split_task_array.append(t)

            t = Task("mer_{0}".format(i), FUNCTION, self.doNothing, task_types, None)
            t._set_state('WAIT')
            merge_task_array.append(t)

            input_array.append([i])

        #inputs_array = InputArray("input", input_array)
        # Sequence
        seq_task_array = TaskArray('Seq Array', seq_task_array)
        seq_result = sequence("Seq Graph Test", seq_task_array, input_array)

        # Split
        split_task_array = TaskArray('Split Array', split_task_array)
        t = Task("spl_first", FUNCTION, self.doNothing, task_types, None)
        split_task = t
        split_result_list = split("Split Graph Test", split_task, [0], split_task_array, input_array)

        # Parallel
        par_task_array = TaskArray('Par Array', par_task_array)
        par_result_list = parallel("Par Graph Test", par_task_array, input_array)

        # Merge
        merge_task_array = TaskArray('Merge Array', merge_task_array)
        t = Task("mer_final", FUNCTION, self.doNothing, task_types, None)
        merge_task = t
        merge_result = merge("Merge Graph Test", merge_task_array, input_array, merge_task, [0])

        end()


if __name__ == "__main__":
    #import sys;sys.argv = ['', 'Test.testName']
    unittest.main()