import sys
from tigres import *
from tigres.utils import TaskFailure, Execution


input1_task1 = "data.csv"
input2_task1 = 5



# Following functions are given 
def task1impl(data_filename, run_number):
    """ Find the average transfer rate"""

    myfd = open(data_filename, 'r')
    average_list = []

    for line in myfd:
        line_split = line.split(',')
        run = int(line_split[2])
        if run_number == run:
            mbs = float(line_split[4])
            average_list.append(mbs)

    total = sum(average_list)
    count = len(average_list)
    average = total / count
    return average


def task2impl(data_filename, average_mbs):
    """ Get the files that are greater than the average transfer rate """
    myfile = open(data_filename, 'r')
    values_greater = []
    myfile.seek(0)
    for line in myfile:
        line_split = line.split(',')
        mbs = float(line_split[4])
        if mbs > average_mbs:
            values_greater.append(line.strip('\r\n'))

    return values_greater


def task3impl(mylist):
    return NotImplemented


def task4impl():
    return NotImplemented


def task5impl():
    return NotImplemented


def task6impl():
    return NotImplemented


def main(execution):
    start(name="Example Workflow FUNCTION", log_dest='example_workflow.log', execution=execution)

    Object_a = input1_task1.__class__

    # Define input types for Task1
    task1_types = InputTypes("Task1types", [Object_a, int])
    # Define Task 1
    task1 = Task("Task1", FUNCTION, task1impl, task1_types, None)
    # Assign inputs for task1
    task1_values = InputValues("Input Task1", [input1_task1, input2_task1])

    # Similarly, define input types and task for task2
    task2_types = InputTypes("Task2types", [Object_a, float])
    task2 = Task("Task2", FUNCTION, task2impl, task2_types, None)
    # Assign values for task2 data.
    # Use "PREVIOUS to mention that task2s second input comes from task1.
    # PREVIOUS by default picks the first output of
    # the previous task in the set.
    # For other specific outputs, the notation
    # 'PREVIOUS.<taskName>.<outputNum>' must be used.
    task2_values = InputValues("Input Task2", [input1_task1, PREVIOUS])

    # Create a task array containing task1 and task2
    task_array12 = TaskArray("sequence tasks12", [task1, task2])
    # Create a data array with task1 and task2's input values
    input_array12 = InputArray("sequence data12", [task1_values, task2_values])

    # Invoke the template
    output_seq = sequence("my seq", task_array12, input_array12)

    if isinstance(output_seq, TaskFailure):
        print((output_seq.error))
        exit()

    print("Sequence Output: \n")
    for o in output_seq:
        print(o)


        # TODO: implement Tasks 3 and 4
        # Object_b=output_seq.__class__
        # Object_c=output_seq.__class__
        #
        #
        # # Task3
        # task3_types = InputTypes("Task3types", [Object_b])
        # task3 = Task("Task3", FUNCTION, task3impl, task3_types, None)
        # task3_values = InputValues("Input task3", [output_seq])
        #
        # # Task 40 to 45 - considering parallel tasks to be identical
        # task4_types = InputTypes("Task4types", [Object_c])
        # task4 = Task("mytask4", FUNCTION, task4impl, task4_types, None)
        # # Create input values for task4's,
        # # where the i-th task gets the i-th output.
        # task4_values  = InputValues("input parallel task", [PREVIOUS.Task3.i])
        #
        # # Create a task array for task4's where task4 will be duplicated based
        # # on number of inputs
        # task_array4 = TaskArray("split tasks 4", [task4])
        # # Create an input array for the task
        # input_array4 = InputArray("split tasks 4 data", [task4_values])
        # # Setup the split template
        # output_split = split("my split", task3, task3_values, task_array4, input_array4)
        #
        # print "Split Output: \n%s\n" % output_split
        #
        # Object_d=output_split.__class__

        # TODO: implement tasks 5 and 6

        # Task50 to Task55
        # - considering parallel tasks to be identical
        # task5_types = InputTypes("Task5Types", [Object_d])
        # task5 = Task("Task5", FUNCTION, task5impl, task5_types, None)
        # task5_values = InputValues("input parallel task",    [output_split])
        #
        # task_array5 = TaskArray("Task 5 array", [task5])
        # input_array5 = InputArray("Task 5 input array", [task5_values])
        #
        # # Task6
        # task6_types = InputTypes("Task6Types", {int})
        # task6 = Task("Task6", FUNCTION, task6impl, task6_types, None)
        # task6_values = InputValues("input task6", [PREVIOUS.Task5.i])

        # Invoke the template
        #workflow_ouput = merge("my sync", task_array5,  input_array5, task6, task6_values)
        #print "Merge Output: \n%s\n" % workflow_ouput

        dot_execution()


if __name__ == "__main__":

    if len(sys.argv) <= 1:
        print(("Usage: {} ({})>".format(sys.argv[0], "|".join(list(Execution.LOOKUP.keys())))))
        exit()
    main(Execution.get(sys.argv[1]))

